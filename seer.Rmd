---
title: "final MA 679"
author: "mary liu"
date: "4/21/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(tidyverse)
```

```{r}
library(readxl)
seer <- read_excel("C:/Users/49431/Downloads/seer project/Health Literacy Transformed Data.xlsx",sheet = "Transformed")
head(seer)
```

# Different Gender



```{r}
sex <- seer[,c(2,15)]

head(sex)

a =ggplot(sex, aes(x = Site, fill = Sex)) +
  stat_count(width = 0.7)
a


```
# Different Region
```{r}
region <- seer[,c(7,15)]
names(region)[names(region) == "SEER Registry"] <- "Region"
head(region)

#sex$group<-as.factor(findInterval(sex$cod, c(1, 4, 7, 10)))

a =ggplot(region, aes(x = Site, fill =Region)) +
  stat_count(width = 0.7) 
a

```

```{r}
library(readxl)
new11 <- read_excel("C:/Users/49431/Downloads/new11.xlsx")
head(new11)
```


```{r}
data = new11[new11$Site.x == "Larynx",]
data
```



#### check the summary data for the data structure
```{r}
summary(data)
str(data)
## there is no missing value ,but exist so many blank values.

```


```{r}
library(readr)
seer_data_full <- read_csv("C:/Users/49431/Downloads/seer_data_full.csv")
head(seer_data_full)
```
#### check the summary data for the data structure
```{r}
summary(seer_data_full)
str(seer_data_full)


```
#### check the blank values for each features
```{r}
blankcheck<-function(x){
  sum(x=="")
}
apply(seer_data_full,2,blankcheck)
```
```{r}

data = seer_data_full%>% mutate_if(is.character,as.factor)
data= as.data.frame(data)
data1 = sapply(data,unclass)%>%as.data.frame()
```
### Missing Values

First We conduct basic data preprocessing. Missing values for dataset are shown in the histogram below.

```{r check_missings}
library(naniar)
data1[data1 == "?"] = NA
# observations contains NA

num3 = complete.cases(data1)
missing = data.frame(data1)
#rownames(missing) = 'missing values'
gg_miss_var(missing) + theme(text = element_text(size=7)) +
  ylab('Number of Missing Values in Each Variable')
```

### Heatmap

Shown in below is a correlation map for the  data that describes the relationship between the different features. 

```{r heatmap}

library(readr)
df_53 <- read_csv("C:/Users/49431/Downloads/df_53.csv")
head(df_53)

df_53 = df_53%>% mutate_if(is.character,as.factor)
df_53= as.data.frame(df_53)
df_53 = sapply(df_53,unclass)%>%as.data.frame()

library(reshape2)
#heatmap plot year3
temp3 = df_53[2:34]
cormat <- round(cor(temp3),2)
melted_cormat <- melt(cormat)
  # Get upper triangle of the correlation matrix
  get_upper_tri <- function(cormat){
    cormat[lower.tri(cormat)]<- NA
    return(cormat)
  }
upper_tri <- get_upper_tri(cormat)
# Melt the correlation matrix
melted_cormat <- melt(upper_tri, na.rm = TRUE)
# Create a ggheatmap
 ggheatmap <- ggplot(melted_cormat, aes(Var2, Var1, fill = value))+
 geom_tile(color = "white")+
 scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
   midpoint = 0, limit = c(-1,1), space = "Lab", 
    name="Pearson\nCorrelation") +
  theme_minimal()+ # minimal theme
 theme(axis.text.x = element_text(angle = 45, vjust = 1, 
    size = 12, hjust = 1))+
 coord_fixed() + ggtitle("seer_data")
# Print the heatmap
aa = ggheatmap + 
theme(axis.text.x = element_text(size=4),
      axis.text.y = element_text(size=4),
  axis.title.x = element_blank(),
  axis.title.y = element_blank(),
  panel.grid.major = element_blank(),
  panel.border = element_blank(),
  panel.background = element_blank(),
  axis.ticks = element_blank(),
  legend.justification = c(1, 0),
  legend.position = c(0.6, 0.7),
  legend.direction = "horizontal")+
  guides(fill = guide_colorbar(barwidth = 7, barheight = 1,
                title.position = "top", title.hjust = 0.5)) +
  scale_y_discrete(position = "right")
aa
ggsave(aa,file="aa.png")
```
# Model

### Split data

To build classification models, we split dataset into training and testing dataset by split ratio = 0.8. We first use training data to fit various classification models, and then use testing data to make predictions and calculate model accuracy. We take seer dataset as an example. 



```{r}
smp_size <- floor(0.7 * nrow(data1))

## set the seed to make partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(data1)), size = smp_size)

train <- data1[train_ind, ]
test <- data1[-train_ind, ]
```

## Lasso Regression and Cross Validation

In lasso regression, we want to test if the lasso can yield either a more accurate or a more interpretable model. We will also use the loss function and cv.glmnet to fit model, and in this time, we will use the argument $$alpha = 1$$. we will fit the lasso regression model:
$$\sum_{i=1}^n(y_i-\beta_0-\sum_j^p\beta_j x_{ij})^2+\lambda\sum_j^p|\beta_j|$$


```{r, error=FALSE}
lasso_cv = cv.glmnet(model.matrix(survive2y~., data=train)[,-1],
                   y = factor(train$survive2y),
                   alpha = 1, 
                   family = 'binomial')
```

```{r}
par(mfrow = c(1,2))
plot(lasso_cv)
plot(lasso_cv$glmnet.fit, "lambda")
bestlam_lasso = lasso_cv$lambda.min
bestlam_lasso
```


```{r}
lasso_pred = predict(lasso_cv,
                     newx = model.matrix(survive2y~., data=test)[,-1],
                     type = 'response')
pred_lasso = ifelse(lasso_pred > 0.5, 1, 0)

table4 = table(pred_lasso, test$survive2y)
rownames(table4) = c('Predicted 0','Predicted 1')
colnames(table4) = c('Actual 0', 'Actual 1')

library(knitr)
kable(table4)

error.lasso = sum(pred_lasso!=test$survive2y)/length(pred_lasso)
error.lasso
```
The error rate is `r error.lasso * 100`%.


##  SVM and Cross Validation

Support Vector Machines is a supervised learing models. It mapped the data as points in the space so that we can separate the data. We want to choose our cross validation set up to use the trainControl function. In the function below we are going to repeat the process 3 times and have 10-folds. After that, we set our trainControl parameters as an input in the 'train' function.

```{r}
coef.result = coef(lasso_cv, s = bestlam_lasso)
dropped = (!(coef(lasso_cv, s = bestlam_lasso)==0)[,1])[-1]
final.coef = names(which(dropped))
```

```{r}
train.selected = train[, which(colnames(train) %in% final.coef)]
test.selected = test[, which(colnames(test) %in% final.coef)]

set.seed(123)

train.selected$survive2y = train$survive2y

trctrl = trainControl(method = "repeatedcv", number = 5, repeats = 3)
svm_fit_3 = train(survive2y ~., data = train.selected, method = "svmRadial",
                  trControl=trctrl, 
                  preProcess = c("center", "scale"), 
                  tuneLength = 5)
```

```{r}
plot(svm_fit_3, col = "red", lwd = 3,
     main = "svm")

pred_svm3 = predict(svm_fit_3,test)
acc_svm3 = mean(pred_svm3 == test$survive2y)

table5 = table(pred_svm3,test$survive2y)
rownames(table5) = c('Predicted 0','Predicted 1')
colnames(table5) = c('Actual 0', 'Actual 1')

kable(table5)

error.svm = sum(pred_svm3!=test$survive2y)/length(pred_svm3)
error.svm
```




##Logistic Regression

```{r}
library(stats)
## make the model with Logistic 
lg<-glm(survive2y~.,family=binomial(link='logit'),data=train)
#summary(lg)
## pred the data with logistic
p_lg<-predict(lg,test,type="response")
p_lg_value<-ifelse(p_lg>=0.5,1,0)

## make the confusion matrix with logistic
table8 = table(p_lg_value, test$survive2y)
rownames(table8) = c('Predicted 0','Predicted 1')
colnames(table8) = c('Actual 0', 'Actual 1')
kable(table8)

error.lg = sum(p_lg_value!=test$survive2y)/length(p_lg)
1-error.lg

```
The error rate is `r error.lg * 100`%.



