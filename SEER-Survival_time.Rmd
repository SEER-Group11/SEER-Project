---
title: "SEER-Survival time"
author: "Group 11"
date: "2021/5/3"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(dplyr)
library(scales)
library(readxl)
library(keras)
library(rsample)
library(tensorflow)
library(caret)
library(naniar)
library(knitr)
library(ggplot2)
library(tidyverse)
library(readr)
library(stats)
library(reshape2)
```

```{r}
data<-read.csv(file="seer_data_full.csv")
```

#EDA
```{r}
#EDA

## SITE
#median month
data %>% 
group_by(Site.x) %>% 
summarise(AverageSurvivalMonth = median(Survival.months)) %>% 
  ggplot(aes(factor(Site.x), AverageSurvivalMonth, label=AverageSurvivalMonth, fill=factor(Site.x))) +
  geom_col() +
  geom_text(nudge_y = 0.5)

#REGION
ggplot(data, 
       aes(x = Site.x, 
           fill = SEERRegistry)) + 
  geom_bar(position = "stack")

ggplot(data, aes(Site.x))+
  geom_bar(aes(fill=SEERRegistry), position="fill")

#AGE
ggplot(data, aes(Site.x))+
  geom_bar(aes(fill=age_range), position="fill")

#race
ggplot(data, aes(Site.x))+
  geom_bar(aes(fill=Race.x), position="fill")

#survive 2 years
ggplot(data, aes(Site.x))+
  geom_bar(aes(fill=as.factor(survive2y)), position="fill")

ggplot(data, aes(Race.x))+
  geom_bar(aes(fill=as.factor(survive2y)), position="fill")

ggplot(data, aes(age_range))+
  geom_bar(aes(fill=as.factor(survive2y)), position="fill")

ggplot(data, aes(size_range))+
  geom_bar(aes(fill=as.factor(survive2y)), position="fill")

ggplot(data,aes(x=Size.x,fill=as.factor(survive2y),color=as.factor(survive2y),group=as.factor(survive2y)))+
  geom_histogram(aes(y = ..density..), alpha = 0.4,position = position_dodge())+
  geom_line(aes(y = ..density..,), stat = 'density',show.legend = F) 

ggplot(data,aes(x=AgeatDiagnosis,fill=as.factor(survive2y),color=as.factor(survive2y),group=as.factor(survive2y)))+
  geom_histogram(aes(y = ..density..), alpha = 0.4,position = position_dodge())+
  geom_line(aes(y = ..density..,), stat = 'density',show.legend = F)

#DISCRIMIMATION
data$surgery_recommendation<-ifelse(data$Surgery.Decision=="Not recommended"|data$Surgery.Decision=="Not recommended, contraindicated due to other cond; autopsy only (1973-2002)",0,1)

plotdata <- data %>%
  group_by(Race.x, surgery_recommendation) %>%
  summarize(n = n()) %>% 
  mutate(pct = n/sum(n),
         lbl = scales::percent(pct))

ggplot(plotdata, aes(Race.x,pct,fill=as.factor(surgery_recommendation)))+
  geom_bar(stat = "identity",
           position = "fill") +
  geom_text(aes(label = lbl), 
            size = 3, 
            position = position_stack(vjust = 0.5))

##less than 2 years compare more than 2 years
data0<-data%>%filter(survive2y==0)
data1<-data%>%filter(survive2y==1)

#race
ggplot(data0, aes(Race.x))+
  geom_bar(aes(fill=as.factor(SurgeryPerformed.)), position="fill")

ggplot(data1, aes(Race.x))+
  geom_bar(aes(fill=as.factor(SurgeryPerformed.)), position="fill")

#size
ggplot() +
  geom_density(aes(Size.x, fill = "dead_within_2_years"), alpha = .2, data = data0) +
  geom_density(aes(Size.x, fill = "survive_more_than_2_years"), alpha = .2, data = data1) +
  scale_fill_manual(name = "dataset", values = c(survive_more_than_2_years = "red", dead_within_2_years = "green"))

#sex
ggplot() +
  geom_bar(aes(Sex.x, fill = "dead_within_2_years",color="black"), alpha = .2, data = data0) +
  geom_bar(aes(Sex.x, fill = "survive_more_than_2_years",color="black"), alpha = .2, data = data1) +
  scale_fill_manual(name = "dataset", values = c(survive_more_than_2_years = "red", dead_within_2_years = "green"))

#region
plotdata <- data0 %>%
  count(SEERRegistry) %>%
  mutate(pct = n / sum(n),
         pctlabel = paste0(round(pct*100), "%"))


ggplot(plotdata, 
       aes(x = reorder(SEERRegistry, -pct),
           y = pct)) + 
  geom_bar(stat = "identity", 
           fill = "indianred3", 
           color = "black") +
  geom_text(aes(label = pctlabel), 
            vjust = -0.25) +
  scale_y_continuous(labels = percent) +
  labs(x = "Region", 
       y = "Percent", 
       title  = "Percent by region")

plotdata1 <- data1 %>%
  count(SEERRegistry) %>%
  mutate(pct = n / sum(n),
         pctlabel = paste0(round(pct*100), "%"))


ggplot(plotdata1, 
       aes(x = reorder(SEERRegistry, -pct),
           y = pct)) + 
  geom_bar(stat = "identity", 
           fill = "indianred3", 
           color = "black") +
  geom_text(aes(label = pctlabel), 
            vjust = -0.25) +
  scale_y_continuous(labels = percent) +
  labs(x = "Region", 
       y = "Percent", 
       title  = "Percent by region")

#age
ggplot(data0, aes(age_range))+
  geom_bar(aes(fill=as.factor(SurgeryPerformed.)), position="fill")

ggplot(data1, aes(age_range))+
  geom_bar(aes(fill=as.factor(SurgeryPerformed.)), position="fill")

ggplot() +
  geom_density(aes(AgeatDiagnosis, fill = "dead_within_2_years"), alpha = .2, data = data0) +
  geom_density(aes(AgeatDiagnosis, fill = "survive_more_than_2_years"), alpha = .2, data = data1) +
  scale_fill_manual(name = "dataset", values = c(survive_more_than_2_years = "red", dead_within_2_years = "green"))

ggplot(data, aes(x=Site.x, y=Size.x, fill=Site.x)) + geom_jitter(aes(colour=Site.x,alpha=0.5),shape=16, position=position_jitter(0.2)) + geom_boxplot(aes(alpha=0.5),outlier.shape = NA)+ stat_summary(fun.y=mean, colour="black", geom="point", hape=18, size=2,show_guide = FALSE)+ stat_summary(fun.y=mean, colour="black", geom="text", show_guide = FALSE, vjust=-0.7, aes( label=round(..y.., digits=1)))+xlab("Disease Site")+   geom_text(data = data, aes(label = count,x = Site.x, y = 100))
```
#MARY

# MARY EDA
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

```{r}

seer_data_fullm <- read_csv("C:/Users/49431/Downloads/seer_data_full.csv")
head(seer_data_fullm)
```
#### check the summary data for the data structure
```{r}
summary(seer_data_fullm)
str(seer_data_fullm)


```
#### check the blank values for each features
```{r}
blankcheck<-function(x){
  sum(x=="")
}
apply(seer_data_fullm,2,blankcheck)
```
```{r}

datam = seer_data_fullm%>% mutate_if(is.character,as.factor)
datam= as.data.frame(datam)
datam = sapply(datam,unclass)%>%as.data.frame()
```
# Different Gender



```{r}
sex <-seer_data_fullm[,c(3,16)]

head(sex)

a =ggplot(sex, aes(x = Site.x, fill = Sex.x)) +
  stat_count(width = 0.7)
a


```
# Different Region
```{r}
region <- seer_data_fullm[,c(8,16)]
names(region)[names(region) == "SEERRegistry"] <- "Region"
head(region)

#sex$group<-as.factor(findInterval(sex$cod, c(1, 4, 7, 10)))

a =ggplot(region, aes(x = Site.x, fill =Region)) +
  stat_count(width = 0.7) 
a

```




#### check the summary data for the data structure
```{r}
summary(datam)
str(datam)
## there is no missing value 

```


### Missing Values

First We conduct basic data preprocessing. Missing values for dataset are shown in the histogram below.

```{r check_missings}

datam[datam == "?"] = NA
# observations contains NA

num3 = complete.cases(datam)
missing = data.frame(datam)
#rownames(missing) = 'missing values'
gg_miss_var(missing) + theme(text = element_text(size=7)) +
  ylab('Number of Missing Values in Each Variable')
```

### Heatmap

Shown in below is a correlation map for the  data that describes the relationship between the different features. 

```{r heatmap}


df_53 <- read_csv("C:/Users/49431/Downloads/df_53.csv")
head(df_53)

df_53 = df_53%>% mutate_if(is.character,as.factor)
df_53= as.data.frame(df_53)
df_53 = sapply(df_53,unclass)%>%as.data.frame()


#heatmap plot year3
temp3 = df_53[2:34]
cormat <- round(cor(temp3),2)
melted_cormat <- melt(cormat)
  # Get upper triangle of the correlation matrix
  get_upper_tri <- function(cormat){
    cormat[lower.tri(cormat)]<- NA
    return(cormat)
  }
upper_tri <- get_upper_tri(cormat)
# Melt the correlation matrix
melted_cormat <- melt(upper_tri, na.rm = TRUE)
# Create a ggheatmap
 ggheatmap <- ggplot(melted_cormat, aes(Var2, Var1, fill = value))+
 geom_tile(color = "white")+
 scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
   midpoint = 0, limit = c(-1,1), space = "Lab", 
    name="Pearson\nCorrelation") +
  theme_minimal()+ # minimal theme
 theme(axis.text.x = element_text(angle = 45, vjust = 1, 
    size = 12, hjust = 1))+
 coord_fixed() + ggtitle("seer_data")
# Print the heatmap
aa = ggheatmap + 
theme(axis.text.x = element_text(size=4),
      axis.text.y = element_text(size=4),
  axis.title.x = element_blank(),
  axis.title.y = element_blank(),
  panel.grid.major = element_blank(),
  panel.border = element_blank(),
  panel.background = element_blank(),
  axis.ticks = element_blank(),
  legend.justification = c(1, 0),
  legend.position = c(0.6, 0.7),
  legend.direction = "horizontal")+
  guides(fill = guide_colorbar(barwidth = 7, barheight = 1,
                title.position = "top", title.hjust = 0.5)) +
  scale_y_discrete(position = "right")
aa
ggsave(aa,file="aa.png")
```
# MARY Model

### Split data

To build classification models, we split dataset into training and testing dataset by split ratio = 0.8. We first use training data to fit various classification models, and then use testing data to make predictions and calculate model accuracy. We take seer dataset as an example. 



```{r}
smp_size <- floor(0.7 * nrow(datam))

## set the seed to make partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(datam)), size = smp_size)

trainm <- datam[train_ind, ]
testm <- datam[-train_ind, ]
```




```{r, error=FALSE}
## Lasso Regression and Cross Validation

#In lasso regression, we want to test if the lasso can yield either a more accurate or a more interpretable model. We will also use the loss function and cv.glmnet to fit model, and in this time, we will use the argument $$alpha = 1$$. we will fit the lasso regression model:
#$$\sum_{i=1}^n(y_i-\beta_0-\sum_j^p\beta_j x_{ij})^2+\lambda\sum_j^p|\beta_j|$$
  
  
#lasso_cv = cv.glmnet(model.matrix(survive2y~., data=trainm)[,-1],
          #         y = factor(trainm$survive2y),
          #         alpha = 1, 
          #         family = 'binomial')
```

```{r}
#par(mfrow = c(1,2))
#plot(lasso_cv)
#plot(lasso_cv$glmnet.fit, "lambda")
#bestlam_lasso = lasso_cv$lambda.min
#bestlam_lasso
```


```{r}
#lasso_pred = predict(lasso_cv,
#                     newx = model.matrix(survive2y~., data=testm)[,-1],
#                     type = 'response')
#pred_lasso = ifelse(lasso_pred > 0.5, 1, 0)

#table4 = table(pred_lasso, testm$survive2y)
#rownames(table4) = c('Predicted 0','Predicted 1')
#colnames(table4) = c('Actual 0', 'Actual 1')

#library(knitr)
#kable(table4)

#error.lasso = sum(pred_lasso!=testm$survive2y)/length(pred_lasso)
#error.lasso

#The error rate is `r error.lasso * 100`%.
```





```{r}
##  SVM and Cross Validation

#Support Vector Machines is a supervised learing models. It mapped the data as points in the space so that we can separate the data. We want to choose our cross validation set up to use the trainControl function. In the function below we are going to repeat the process 3 times and have 10-folds. After that, we set our trainControl parameters as an input in the 'train' function.


#coef.result = coef(lasso_cv, s = bestlam_lasso)
#dropped = (!(coef(lasso_cv, s = bestlam_lasso)==0)[,1])[-1]
#final.coef = names(which(dropped))
```

```{r}
#train.selected = trainm[, which(colnames(trainm) %in% final.coef)]
#test.selected = testm[, which(colnames(testm) %in% final.coef)]

#set.seed(123)

#train.selected$survive2y = trainm$survive2y

#trctrl = trainControl(method = "repeatedcv", number = 5, repeats = 3)
#svm_fit_3 = train(survive2y ~., data = train.selected, method = "svmRadial",
#                  trControl=trctrl, 
#                  preProcess = c("center", "scale"), 
#                  tuneLength = 5)
```

```{r}
#plot(svm_fit_3, col = "red", lwd = 3,
#     main = "svm")

#pred_svm3 = predict(svm_fit_3,testm)
#acc_svm3 = mean(pred_svm3 == testm$survive2y)

#table5 = table(pred_svm3,testm$survive2y)
#rownames(table5) = c('Predicted 0','Predicted 1')
#colnames(table5) = c('Actual 0', 'Actual 1')

#kable(table5)

#error.svm = sum(pred_svm3!=testm$survive2y)/length(pred_svm3)
#error.svm
```




##Logistic Regression

```{r}


## make the model with Logistic 
lg<-glm(survive2y~.,family=binomial(link='logit'),data=trainm)
#summary(lg)
## pred the data with logistic
p_lg<-predict(lg,testm,type="response")
p_lg_value<-ifelse(p_lg>=0.5,1,0)

## make the confusion matrix with logistic
table8 = table(p_lg_value, testm$survive2y)
rownames(table8) = c('Predicted 0','Predicted 1')
colnames(table8) = c('Actual 0', 'Actual 1')


kable(table8)

error.lg = sum(p_lg_value!=testm$survive2y)/length(p_lg)
1-error.lg

```  
#GUA
  
#CHI
 ```{r}
datac <- data%>%mutate_if(is.character,as.factor)
datac <- as.data.frame(datac)
data_new <- sapply(datac,unclass)%>%as.data.frame()

set.seed(100)
train_test_split <- initial_split(data_new, prop = 0.7)
trainc <- training(train_test_split)
testc  <- testing(train_test_split) 
train_yc <- as.matrix(trainc["survive2y"])
test_yc <- as.matrix(testc["survive2y"])
train_xc <- as.matrix(trainc[,-47])
train_xc <-scale(train_xc)
test_xc <- as.matrix(testc[,-47])
test_xc <-scale(test_xc)
```

```{r}
set_random_seed(42)
one_hot_train_labels <- to_categorical(train_yc)
one_hot_test_labels <- to_categorical(test_yc)
head(one_hot_train_labels)
model <- keras_model_sequential() %>%
  layer_dense(units = 256, activation = "relu",input_shape = ncol(train_xc)) %>%
  layer_dropout(rate = 0.6) %>%
  layer_dense(units = 128, activation = "relu") %>%
  layer_dense(units = ncol(one_hot_train_labels), activation = "sigmoid")

model %>% compile(
  optimizer = "adam",
  loss = "binary_crossentropy",
  metrics = c("accuracy")
)

history <-model %>% fit(train_xc, one_hot_train_labels, epochs = 100,batch_size = 512, validation_split = 0.2)
plot(history)
```

```{r}
set_random_seed(42)
model1 <- keras_model_sequential() %>%
  layer_dense(units = 256, activation = "relu",input_shape = ncol(train_xc)) %>%
 layer_dropout(rate = 0.6) %>%
  layer_dense(units = 128, activation = "relu") %>%
  layer_dense(units = 2, activation = "sigmoid")

model1 %>% compile(
  optimizer = "adam",
  loss = "binary_crossentropy",
  metrics = c("accuracy")
)

history1 <-model1 %>% fit(train_xc, one_hot_train_labels, epochs = 65,batch_size = 512)
results <- model1 %>% evaluate(test_xc, one_hot_test_labels)
results
plot(history1)
```

```{r}
predc <-model1%>%predict(test_xc)%>%round()
confusionMatrix(as.factor(predc),as.factor(one_hot_test_labels))
```

